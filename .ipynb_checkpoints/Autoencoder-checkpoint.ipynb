{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "\n",
    "num_layers = 1\n",
    "num_steps = 1\n",
    "input_size = 1\n",
    "embed_size = 1\n",
    "learning_rate = 0.0000001\n",
    "num_lstm = 512\n",
    "random_wav = \"bass_electronic_018-022-100.wav\"\n",
    "\n",
    "audio = utils.load_audio(random_wav)\n",
    "sample_length = audio.shape[0]\n",
    "print(sample_length)\n",
    "audio = np.concatenate((audio, audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#normalized does not work\n",
    "class dt():\n",
    "    def __init__(self, raw_audio, input_size = input_size, num_steps = num_steps, test_ratio = 0.1, normalized = False):\n",
    "        self.raw_seq = np.array(raw_audio)\n",
    "        self.input_size = input_size\n",
    "        self.num_steps = num_steps \n",
    "        self.test_ratio = test_ratio\n",
    "        self.normalized = normalized\n",
    "        self.train_X, self.train_y, self.test_X, self.test_y = self._prepare_data(self.raw_seq)\n",
    "\n",
    "    def _prepare_data(self, seq):\n",
    "        # split into items of input_size\n",
    "        seq = [np.array(seq[i * self.input_size: (i + 1) * self.input_size])\n",
    "               for i in range(len(seq) // self.input_size)]\n",
    "        \n",
    "        if self.normalized:\n",
    "            seq = [seq[0] / seq[0][0] - 1.0] + [\n",
    "                curr / seq[i][-1] - 1.0 for i, curr in enumerate(seq[1:])]\n",
    "\n",
    "        # split into groups of num_steps\n",
    "        X = np.array([seq[i: i + self.num_steps] for i in range(len(seq) - self.num_steps)])\n",
    "        y = np.array([seq[i + self.num_steps] for i in range(len(seq) - self.num_steps)])\n",
    "\n",
    "        train_size = int(len(X) * (1.0 - self.test_ratio))\n",
    "        train_X, test_X = X[:train_size], X[train_size:]\n",
    "        train_y, test_y = y[:train_size], y[train_size:]\n",
    "        return train_X, train_y, test_X, test_y\n",
    "\n",
    "    def generate_one_epoch(self, batch_size):\n",
    "        num_batches = int(len(self.train_X)) // batch_size\n",
    "        if batch_size * num_batches < len(self.train_X):\n",
    "            num_batches += 1\n",
    "\n",
    "        batch_indices = list(range(num_batches))\n",
    "        random.shuffle(batch_indices)\n",
    "        for j in batch_indices:\n",
    "            batch_X = self.train_X[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_y = self.train_y[j * batch_size: (j + 1) * batch_size]\n",
    "            assert set(map(len, batch_X)) == {self.num_steps}\n",
    "            yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "#time, batch, depth\n",
    "encoder_inputs_t = tf.placeholder(shape=(None, num_steps, input_size), dtype=tf.float32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, input_size), dtype=tf.float32, name='decoder_targets')\n",
    "decoder_inputs_t = tf.placeholder(shape=(None, num_steps, input_size), dtype=tf.float32, name='decoder_inputs')\n",
    "\n",
    "\n",
    "decoder_inputs = tf.transpose(decoder_inputs_t, [1, 0, 2])\n",
    "encoder_inputs = tf.transpose(encoder_inputs_t, [1, 0, 2])\n",
    "cell = tf.contrib.rnn.LSTMCell(num_lstm)\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    cell, encoder_inputs,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    cell, decoder_inputs,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "#output_shape = tf.shape(decoder_outputs)\n",
    "prediction = tf.nn.softmax(tf.reshape(decoder_outputs, [-1, input_size])) #TODO: why?\n",
    "#print(tf.shape(prediction))\n",
    "loss = tf.reduce_mean((tf.square(decoder_outputs - encoder_inputs)))\n",
    "optimizer =  tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.66711e-05\n",
      "1.24013e-05\n",
      "1.75355e-06\n",
      "1.25893e-07\n",
      "3.69617e-05\n",
      "2.69044e-08\n",
      "6.28427e-09\n",
      "8.1058e-08\n",
      "3.18843e-08\n",
      "4.2178e-08\n",
      "7.76354e-07\n",
      "2.61135e-07\n",
      "1.00573e-07\n",
      "Final test_loss is 0.000453359\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    merged_test_X = np.array(audio)\n",
    "    merged_test_y = np.array(audio)\n",
    "\n",
    "    global_step = 0\n",
    "    epoch_step = 0\n",
    "    d = dt(audio, test_ratio=0)\n",
    "    \n",
    "    for batch_x, batch_y in d.generate_one_epoch(batch_size):\n",
    "        global_step += 1\n",
    "        epoch_step += 1\n",
    "        batch_labels = np.ones(batch_x.shape)\n",
    "        train_data_feed = {\n",
    "            encoder_inputs_t: batch_x,\n",
    "            decoder_targets: batch_y,\n",
    "            decoder_inputs_t: batch_labels,\n",
    "        }\n",
    "        #print(sess.run(tf.shape(decoder_outputs),train_data_feed))\n",
    "        train_loss, _ = sess.run([loss, optimizer], train_data_feed)\n",
    "        if(global_step % 100 == 1):\n",
    "            print(train_loss)\n",
    "    batch_labels = np.ones(d.train_X.shape)\n",
    "    test_data_feed = {\n",
    "            encoder_inputs_t: d.train_X,\n",
    "            decoder_targets: d.train_y,\n",
    "            decoder_inputs_t: batch_labels,\n",
    "    }\n",
    "    test_loss, test_pred = sess.run([loss, prediction], test_data_feed)\n",
    "    print(\"Final test_loss is \" + str(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _flatten(seq):\n",
    "    return [x for y in seq for x in y]\n",
    "\n",
    "truths = np.array(audio[:-1])\n",
    "preds = np.array(_flatten(test_pred))\n",
    "print(truths.shape)\n",
    "print(preds.shape)\n",
    "days = np.array(range(len(truths))[-127999:])\n",
    "print(days.shape)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(days, truths, label='truth')\n",
    "plt.plot(days, preds, label='pred')\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"amplitute\")\n",
    "plt.ylim((min(truths), max(truths)))\n",
    "plt.grid(ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
