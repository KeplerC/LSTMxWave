{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "random_wav = \"bass_electronic_018-022-100.wav\"\n",
    "\n",
    "audio = utils.load_audio(random_wav)\n",
    "sample_length = audio.shape[0]\n",
    "print(sample_length)\n",
    "audio = np.concatenate((audio, audio))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00   6.10351562e-05   2.13623047e-04 ...,   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJamGDH9JqqH/D6RlUGqnTbcaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbba63bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(audio)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(audio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"truediv_1:0\", shape=(128000,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "learning_rate = 0.00001\n",
    "num_lstm = 512\n",
    "with tf.Graph().as_default():\n",
    "    #session_config = tf.Config\n",
    "    with tf.Session() as sess:\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(num_lstm)\n",
    "        #initial_state = tf.zeros([batch_size, lstm.state_size])\n",
    "        \n",
    "#encode with 8 bit mu-law\n",
    "x = audio\n",
    "x_quantized = utils.mu_law(x)\n",
    "x_scaled = x_quantized / 128\n",
    "num_z = 16\n",
    "print(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "num_steps = 1\n",
    "input_size = 1\n",
    "lstm_size = 128\n",
    "keep_prob = 1\n",
    "stock_count = 1\n",
    "embed_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keplerc/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#official tutorial: words_in_dataset = tf.placeholder(tf.float32, [time_steps, batch_size, num_features])\n",
    "learning_rate = tf.placeholder(tf.float32, None, name=\"learning_rate\")\n",
    "# symbols are mapped to integers.\n",
    "symbols = tf.placeholder(tf.int32, [None, 1], name='symbols')\n",
    "inputs = tf.placeholder(tf.float32, [None, num_steps, input_size], name=\"inputs\")\n",
    "\n",
    "#inputs = tf.reshape(inputs, tf.TensorShape([64000,1,1]))\n",
    "targets = tf.placeholder(tf.float32, [None, input_size], name=\"targets\")\n",
    "\n",
    "def _create_one_cell():\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(lstm_size, state_is_tuple=True)\n",
    "    '''\n",
    "    if keep_prob < 1.0:\n",
    "        lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell, output_keep_prob=keep_prob)    '''\n",
    "    return lstm_cell\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell([_create_one_cell() for _ in range(num_layers)],state_is_tuple=True\n",
    ") if num_layers > 1 else _create_one_cell()\n",
    "\n",
    "\n",
    "#embedding layer\n",
    "embed_matrix = tf.Variable(\n",
    "    tf.random_uniform([stock_count, embed_size], -1.0, 1.0),\n",
    "    name=\"embed_matrix\"\n",
    ")\n",
    "sym_embeds = tf.nn.embedding_lookup(embed_matrix, symbols)\n",
    "            \n",
    "# stock_label_embeds.shape = (batch_size, embedding_size)\n",
    "stacked_symbols = tf.tile(symbols, [1, num_steps], name='stacked_stock_labels')\n",
    "stacked_embeds = tf.nn.embedding_lookup(embed_matrix, stacked_symbols)\n",
    "\n",
    "# After concat, inputs.shape = (batch_size, num_steps, lstm_size + embed_size)\n",
    "inputs_with_embed = tf.concat([inputs, stacked_embeds], axis=2, name=\"inputs_with_embed\")\n",
    "\n",
    "val, state_ = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32, scope=\"dynamic_rnn\")\n",
    "\n",
    "# Before transpose, val.get_shape() = (batch_size, num_steps, lstm_size)\n",
    "# After transpose, val.get_shape() = (num_steps, batch_size, lstm_size)\n",
    "val = tf.transpose(val, [1, 0, 2])\n",
    "last = tf.gather(val, int(val.get_shape()[0]) - 1, name=\"lstm_state\")\n",
    "ws = tf.Variable(tf.truncated_normal([lstm_size, input_size]), name=\"w\")\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[input_size]), name=\"b\")\n",
    "pred = tf.matmul(last, ws) + bias\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(pred - targets), name=\"loss_mse\")\n",
    "optim = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, name=\"rmsprop_optim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   6.10351562e-05,   2.13623047e-04, ...,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = utils.load_audio(random_wav)\n",
    "audio = list(map(lambda x: x, audio))\n",
    "np.array(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#normalized does not work\n",
    "class dt():\n",
    "    def __init__(self, raw_audio, input_size = input_size, num_steps = num_steps, test_ratio = 0.1, normalized = False):\n",
    "        self.raw_seq = np.array(raw_audio)\n",
    "        self.input_size = input_size\n",
    "        self.num_steps = num_steps \n",
    "        self.test_ratio = test_ratio\n",
    "        self.normalized = normalized\n",
    "        self.train_X, self.train_y, self.test_X, self.test_y = self._prepare_data(self.raw_seq)\n",
    "\n",
    "    def _prepare_data(self, seq):\n",
    "        # split into items of input_size\n",
    "        seq = [np.array(seq[i * self.input_size: (i + 1) * self.input_size])\n",
    "               for i in range(len(seq) // self.input_size)]\n",
    "        \n",
    "        if self.normalized:\n",
    "            seq = [seq[0] / seq[0][0] - 1.0] + [\n",
    "                curr / seq[i][-1] - 1.0 for i, curr in enumerate(seq[1:])]\n",
    "\n",
    "        # split into groups of num_steps\n",
    "        X = np.array([seq[i: i + self.num_steps] for i in range(len(seq) - self.num_steps)])\n",
    "        y = np.array([seq[i + self.num_steps] for i in range(len(seq) - self.num_steps)])\n",
    "\n",
    "        train_size = int(len(X) * (1.0 - self.test_ratio))\n",
    "        train_X, test_X = X[:train_size], X[train_size:]\n",
    "        train_y, test_y = y[:train_size], y[train_size:]\n",
    "        return train_X, train_y, test_X, test_y\n",
    "\n",
    "    def generate_one_epoch(self, batch_size):\n",
    "        num_batches = int(len(self.train_X)) // batch_size\n",
    "        if batch_size * num_batches < len(self.train_X):\n",
    "            num_batches += 1\n",
    "\n",
    "        batch_indices = list(range(num_batches))\n",
    "        random.shuffle(batch_indices)\n",
    "        for j in batch_indices:\n",
    "            batch_X = self.train_X[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_y = self.train_y[j * batch_size: (j + 1) * batch_size]\n",
    "            assert set(map(len, batch_X)) == {self.num_steps}\n",
    "            yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00996972\n",
      "0.00991638\n",
      "0.00982873\n",
      "0.00964791\n",
      "0.00949599\n",
      "0.00922794\n",
      "0.00920783\n",
      "0.00854127\n",
      "0.00817318\n",
      "0.00779475\n",
      "0.00742483\n",
      "0.00708643\n",
      "0.00671388\n",
      "0.00635843\n",
      "0.00601442\n",
      "0.00567504\n",
      "0.00536003\n",
      "0.00504839\n",
      "0.0047484\n",
      "0.0044527\n",
      "0.00416741\n",
      "0.00389149\n",
      "0.00362551\n",
      "0.00336865\n",
      "0.0031216\n",
      "0.00288468\n",
      "0.00265679\n",
      "0.00243596\n",
      "0.00223002\n",
      "0.00203219\n",
      "0.00184449\n",
      "0.0016632\n",
      "0.00149494\n",
      "0.00133301\n",
      "0.00118116\n",
      "0.00103956\n",
      "0.000906802\n",
      "0.000784637\n",
      "0.0481672\n",
      "0.000656264\n",
      "0.00056345\n",
      "0.000472101\n",
      "0.000380948\n",
      "0.000353106\n",
      "0.000313596\n",
      "0.000265665\n",
      "0.000214321\n",
      "0.000162952\n",
      "0.000118137\n",
      "8.09437e-05\n",
      "5.14075e-05\n",
      "2.93961e-05\n",
      "1.43797e-05\n",
      "5.51477e-06\n",
      "1.63645e-06\n",
      "1.85324e-07\n",
      "2.0358e-07\n",
      "7.36123e-10\n",
      "3.75426e-10\n",
      "9.27099e-11\n",
      "2.68015e-10\n",
      "2.48144e-09\n",
      "4.13544e-07\n",
      "1.80223e-07\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "batch_labels = np.ones([batch_size,1])\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    merged_test_X = np.array(audio)\n",
    "    merged_test_y = np.array(audio)\n",
    "\n",
    "    global_step = 0\n",
    "    epoch_step = 0\n",
    "    d = dt(audio, test_ratio=0)\n",
    "    for batch_x, batch_y in d.generate_one_epoch(batch_size):\n",
    "        global_step += 1\n",
    "        epoch_step += 1\n",
    "        train_data_feed = {\n",
    "            learning_rate : 0.00001,\n",
    "            inputs: batch_x,\n",
    "            targets: batch_y,\n",
    "            symbols: batch_labels,\n",
    "        }\n",
    "        train_loss, _ = sess.run([loss, optim], train_data_feed)\n",
    "        if(global_step % 10 == 0):\n",
    "            print(train_loss)\n",
    "    \n",
    "    test_data_feed = {\n",
    "            learning_rate : 0.00001,\n",
    "            inputs: d.train_X,\n",
    "            targets: d.train_y,\n",
    "            symbols: batch_labels,\n",
    "    }\n",
    "    test_loss, test_pred = sess.run([loss, pred], test_data_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00038607]\n",
      " [-0.00038524]\n",
      " [-0.00038315]\n",
      " ..., \n",
      " [-0.00038607]\n",
      " [-0.00038607]\n",
      " [-0.00038607]]\n"
     ]
    }
   ],
   "source": [
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63999,)\n",
      "(63999,)\n",
      "(63999,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtwAAAF3CAYAAACWmpzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63d3f46ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _flatten(seq):\n",
    "    return [x for y in seq for x in y]\n",
    "\n",
    "truths = np.array(audio[:-1])\n",
    "preds = np.array(_flatten(test_pred))\n",
    "print(truths.shape)\n",
    "print(preds.shape)\n",
    "days = np.array(range(len(truths))[-127999:])\n",
    "print(days.shape)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(days, truths, label='truth')\n",
    "plt.plot(days, preds, label='pred')\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"amplitute\")\n",
    "plt.ylim((min(truths), max(truths)))\n",
    "plt.grid(ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (1, 1, 20) must have rank 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    575\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0mnew_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_same_rank\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Shapes %s and %s must have the same rank\" % (self,\n\u001b[0;32m--> 621\u001b[0;31m                                                                        other))\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (1, 1, 20) and (?, ?) must have the same rank",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    581\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are not compatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (1, 1, 20) and (?, ?) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ee72adf2f962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n\u001b[1;32m     23\u001b[0m     \u001b[0mencoder_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_inputs_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    775\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[1;32m   2814\u001b[0m     \u001b[0mloop_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=redefined-outer-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2816\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2817\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2638\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2640\u001b[0;31m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2641\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2588\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m-> 2590\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    760\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    761\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;31m# Pack state if using state tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    181\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[1;32m    182\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0min_graph_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m     \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not infer input size from inputs.get_shape()[-1]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    651\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwith_rank_at_least\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (1, 1, 20) must have rank 2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units * 2\n",
    "#time, batch, depth\n",
    "encoder_inputs = tf.placeholder(shape=(None, num_steps, input_size), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, input_size), dtype=tf.int32, name='decoder_targets')\n",
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)\n",
    "\n",
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "print(encoder_final_state)\n",
    "print(decoder_inputs_embedded)\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")\n",
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)\n",
    "\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMStateTuple(c=<tf.Tensor 'dynamic_rnn/while/Exit_2:0' shape=(?, 128) dtype=float32>, h=<tf.Tensor 'dynamic_rnn/while/Exit_3:0' shape=(?, 128) dtype=float32>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"Reshape:0\", shape=(?, ?), dtype=float32) must be from the same graph as Tensor(\"Reshape:0\", shape=(100, 10), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-16bb7c75deee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n\u001b[1;32m     27\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, dim, name)\u001b[0m\n\u001b[1;32m   1781\u001b[0m   \u001b[0;31m# _CrossEntropyGrad() in nn_grad but not here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m   cost, unused_backprop = gen_nn_ops._softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 1783\u001b[0;31m       precise_logits, labels, name=name)\n\u001b[0m\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m   \u001b[0;31m# The output cost shape should be the input minus dim.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m_softmax_cross_entropy_with_logits\u001b[0;34m(features, labels, name)\u001b[0m\n\u001b[1;32m   4362\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4363\u001b[0m         \u001b[0;34m\"SoftmaxCrossEntropyWithLogits\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4364\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4365\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4366\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   4634\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4635\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4636\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4637\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4638\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   4570\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4571\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[0;32m-> 4572\u001b[0;31m                                                                 original_item))\n\u001b[0m\u001b[1;32m   4573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"Reshape:0\", shape=(?, ?), dtype=float32) must be from the same graph as Tensor(\"Reshape:0\", shape=(100, 10), dtype=float32)."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 100\n",
    "#official tutorial: words_in_dataset = tf.placeholder(tf.float32, [time_steps, batch_size, num_features])\n",
    "inputs = tf.placeholder(tf.float32, [None, num_steps, input_size], name=\"inputs\")\n",
    "inputs_t = tf.transpose(inputs, [1, 0, 2])\n",
    "targets = tf.placeholder(tf.float32, [None, input_size], name=\"targets\")\n",
    "\n",
    "cell = tf.contrib.rnn.LSTMCell(lstm_size, state_is_tuple=True)\n",
    "val, encoder_final_state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32, scope=\"dynamic_rnn\")\n",
    "\n",
    "# Before transpose, val.get_shape() = (batch_size, num_steps, lstm_size)\n",
    "# After transpose, val.get_shape() = (num_steps, batch_size, lstm_size)\n",
    "print(encoder_final_state)\n",
    "decoder_outputs = tf.ones((num_steps, batch_size, lstm_size))\n",
    "'''\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    cell, decoder_inputs,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")\n",
    "'''\n",
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)\n",
    "\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "#sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
